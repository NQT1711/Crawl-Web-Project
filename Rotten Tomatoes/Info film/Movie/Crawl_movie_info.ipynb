{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from warnings import warn\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pytz import timezone\n",
    "from IPython.display import clear_output\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trình duyệt Google Chrome ở trang thái Tab ẩn danh\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "s = Service('C:\\chromedriver')\n",
    "driver = webdriver.Chrome(service=s, options=options)\n",
    "driver.implicitly_wait(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tất cả url movie\n",
    "list_all_url_movie = pd.read_csv('E:/Crawl_Web/Rotten Tomatoes/Crawl URL/URL_movie.csv').squeeze('columns').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.rottentomatoes.com/m/fury-river\n",
      "https://www.rottentomatoes.com/m/children_of_the_corn_revelation\n",
      "https://www.rottentomatoes.com/m/exhibition_on_screen_the_artists_garden_american_impressionism_2017\n",
      "https://www.rottentomatoes.com/m/roja\n",
      "https://www.rottentomatoes.com/m/goodbye_christopher_robin\n",
      "https://www.rottentomatoes.com/m/tomorrow-morning-sutra-ujutru\n",
      "https://www.rottentomatoes.com/m/beauty-and-the-beast-the-enchanted-christmas\n",
      "https://www.rottentomatoes.com/m/sasaki_in_my_mind\n",
      "https://www.rottentomatoes.com/m/kurt_vonnegut_unstuck_in_time\n"
     ]
    }
   ],
   "source": [
    "df_movie = []\n",
    "\n",
    "for url_movie in list_all_url_movie[:1000]:\n",
    "    # Mở url phim\n",
    "    driver.get(url_movie)\n",
    "    \n",
    "    try:\n",
    "        # Đợi cho đến khi url load xong\n",
    "        element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"main_container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element)\n",
    "        soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        sleep(2)\n",
    "\n",
    "        ## Tạo Dict chứa thông tin về phim\n",
    "        dict_info_movie = {}\n",
    "\n",
    "        # Tiêu đề phim\n",
    "        dict_info_movie['Title'] = soup.select('h1[class=\"scoreboard__title\"]')[0].text\n",
    "\n",
    "        # Điểm đánh giá của nhà phê bình\n",
    "        dict_info_movie['Tomatometer score'] = soup.select('score-board')[0].attrs['tomatometerscore']\n",
    "\n",
    "        # Điểm đánh giá của khán giả\n",
    "        dict_info_movie['Audience score'] = soup.select('score-board')[0].attrs['audiencescore']\n",
    "\n",
    "        # Số lượt đánh giá của nhà phê bình\n",
    "        dict_info_movie['Tomatometer count'] = soup.select('a[slot=\"critics-count\"]')[0].text.strip()\n",
    "\n",
    "        # Số lượt đánh giá của khán giả\n",
    "        dict_info_movie['Audience count'] = soup.select('a[slot=\"audience-count\"]')[0].text.strip()\n",
    "\n",
    "        # Trạng thái đánh giá phim của nhà phê bình\n",
    "        dict_info_movie['Tomatometer state'] = soup.select('score-board')[0].attrs['tomatometerstate']\n",
    "\n",
    "        # Trạng thái đánh giá phim của khán giả\n",
    "        dict_info_movie['Audience state'] = soup.select('score-board')[0].attrs['audiencestate']\n",
    "\n",
    "        # Thông tin phim\n",
    "        list_name_info = soup.select('div[class=\"meta-label subtle\"]')\n",
    "        list_info = soup.select('div[data-qa=\"movie-info-item-value\"]')\n",
    "\n",
    "        for num_info in range(len(list_name_info)):\n",
    "            name_info = list_name_info[num_info].text.replace('  ', '').replace('\\n', '').replace(':', '')\n",
    "            info = list_info[num_info].text.replace('  ', '').replace('\\n', '').replace(':', '')\n",
    "            dict_info_movie[name_info] = info\n",
    "\n",
    "        # Tóm tắt nội dụng phim\n",
    "        dict_info_movie['Synopsis'] = soup.select('div[id=\"movieSynopsis\"]')[0].text.strip()\n",
    "\n",
    "        # Diễn viên\n",
    "        list_raw_cast = soup.select('span[class=\"characters subtle smaller\"]')\n",
    "        list_cast = []\n",
    "\n",
    "        for c in list_raw_cast:\n",
    "            list_cast.append(c.attrs['title'])\n",
    "\n",
    "        dict_info_movie['Cast'] = ', '.join(list_cast)\n",
    "\n",
    "        df_movie.append(dict_info_movie)\n",
    "\n",
    "        # Reviews của nhà phê bình\n",
    "        driver.get(url_movie + '/reviews')\n",
    "\n",
    "        element_critic_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class=\"layout reviews-page-container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_critic_review)\n",
    "        soup_critic_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        ## Check có review của nhà phê bình không ?\n",
    "        check_critic_review = soup_critic_review.select('div[class=\"review_table\"]')[0].text.strip()\n",
    "\n",
    "        if check_critic_review != '':\n",
    "            list_critic_review = []\n",
    "            \n",
    "            for rv in soup_critic_review.select('p[class=\"review-text\"]'):\n",
    "                list_critic_review.append(rv.text)\n",
    "            \n",
    "            while True:\n",
    "                sleep(1)\n",
    "                try:\n",
    "                    next_button = driver.find_element_by_css_selector('rt-button[class=\"js-prev-next-paging-next\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    \n",
    "                    element_critic_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class=\"review_table\"]')))\n",
    "                    html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_critic_review)\n",
    "                    soup_critic_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "                    for rv in soup_critic_review.select('p[class=\"review-text\"]'):\n",
    "                        list_critic_review.append(rv.text.replace('  ', ''))\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "            dict_info_movie['Critic review'] = '<>'.join(list_critic_review)\n",
    "        elif check_critic_review == '':\n",
    "            dict_info_movie['Critic review'] = 'Không có review của nhà phê bình'\n",
    "\n",
    "        # Reviews của khán giả\n",
    "        driver.get(url_movie + '/reviews?type=user')\n",
    "\n",
    "        element_audience_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-qa=\"reviews-container\"]')))\n",
    "        html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_audience_review)\n",
    "        soup_audience_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "        ## Check có review của khán giả không ?\n",
    "        check_audience_review = soup_audience_review.select('div[id=\"movieUserReviewsContent\"]')\n",
    "\n",
    "        if len(check_audience_review) != 0:\n",
    "            list_audience_review = []\n",
    "            \n",
    "            for rv in soup_audience_review.select('p[data-qa=\"review-text\"]'):\n",
    "                list_audience_review.append(rv.text)\n",
    "            \n",
    "            while True:\n",
    "                sleep(1)\n",
    "                try:\n",
    "                    next_button = driver.find_element_by_css_selector('rt-button[class=\"js-prev-next-paging-next\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    \n",
    "                    element_audience_review = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"movieUserReviewsContent\"]')))\n",
    "                    html_of_interest = driver.execute_script('return arguments[0].innerHTML',element_audience_review)\n",
    "                    soup_audience_review = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "                    for rv in soup_audience_review.select('p[data-qa=\"review-text\"]'):\n",
    "                        list_audience_review.append(rv.text)\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "            dict_info_movie['Audience review'] = '<>'.join(list_audience_review)\n",
    "        else:\n",
    "            dict_info_movie['Audience review'] = 'Không có review của khán giả'\n",
    "\n",
    "    except:\n",
    "        print(url_movie)\n",
    "        continue\n",
    "    \n",
    "df_movie = pd.DataFrame(df_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.to_csv('Crawl_test_1000_movie.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
